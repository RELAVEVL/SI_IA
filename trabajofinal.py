# -*- coding: utf-8 -*-
"""TrabajoFinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/175UGSPxG7WPHEwAwq9TPJNs6LebhNWn1
"""

import pandas as pd
import os
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.base import TransformerMixin

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

# Leemos el csv por medio de pandas
df_RUIAS_os = pd.read_csv('/content/sample_data/1a_RUIAS.csv', sep=';', encoding='utf-8')

# Eliminamos columnas no deseadas
columnas_borrar = [
    "N", "NOMBRE_ADMINISTRADO", "NOMBRE_UNIDAD_FISCALIZABLE", "NRO_EXPEDIENTE", "NRO_RD", "DETALLE_INFRACCION",
    "TIPO_SANCION", "ACTO_RESUELVE", "FECHA_ACTO", "FECHA_CORTE", "TIPO_DOC", "NORMA_TIPIFICADORA", "MEDIDA_DICTADA",
    "NRO_RD_MULTA", "FECHA_RD_MULTA", "TIPO_RECURSO_IMPUGNATIVO", "CANTIDAD_MULTA", "CANTIDAD_INFRACCIONES", "MULTA_EXPEDIENTE"
]

# Verificar las columnas presentes en el DataFrame
columnas_existentes = [col for col in columnas_borrar if col in df_RUIAS_os.columns]

# Eliminar columnas no deseadas que existen en el DataFrame
df_RUIAS_os.drop(columns=columnas_existentes, inplace=True)

# Eliminar filas donde 'DEPARTAMENTO' es "-"
df_RUIAS_os = df_RUIAS_os[df_RUIAS_os['DEPARTAMENTO'] != "-"]

# Departamentos a filtrar
departamentos_interes = ["Loreto", "Ucayali", "Madre de Dios", "Amazonas", "San Martín"]

# Crear una expresión regular para buscar los departamentos ignorando caracteres adicionales
regex_pattern = '|'.join([f'.*{dept}.*' for dept in departamentos_interes])

# Filtrar el DataFrame para que solo contenga filas de los departamentos especificados
data_frame_filtrado = df_RUIAS_os[df_RUIAS_os['DEPARTAMENTO'].str.contains(regex_pattern, case=False, na=False)]

# Selección de columnas
columnas_seleccionadas = [
    "ID_DOC_ADMINISTRADO",
    "SUBSECTOR_ECONOMICO",
    "DEPARTAMENTO",
    "PROVINCIA",
    "DISTRITO",
    "FECHA_RD",
    "FECHA_INICIO_SUP",
    "FECHA_FIN_SUP",
    "TIPO_INFRACCION"
]

data_frame_seleccionado = data_frame_filtrado[columnas_seleccionadas]

# Binarización de categorías
def binarize_column(data_frame, column_name):
    unique_values = data_frame[column_name].nunique()
    if unique_values > 2:
        encoder = OneHotEncoder(sparse_output=False)  # Cambiado de 'sparse' a 'sparse_output'
        encoded_columns = encoder.fit_transform(data_frame[[column_name]])
        encoded_columns_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out([column_name]))
    else:
        encoder = LabelBinarizer()
        encoded_columns = encoder.fit_transform(data_frame[column_name])
        encoded_columns_df = pd.DataFrame(encoded_columns, columns=[f"{column_name}_BIN"])
    return encoded_columns_df

# Aplicar binarización a las columnas
columns_to_binarize = ['SUBSECTOR_ECONOMICO', 'DEPARTAMENTO', 'TIPO_INFRACCION']
for column in columns_to_binarize:
    encoded_df = binarize_column(data_frame_seleccionado, column)
    data_frame_seleccionado = data_frame_seleccionado.join(encoded_df)

# Extraer columnas específicas
columns_to_extract = ["ID_DOC_ADMINISTRADO"] + \
    [col for col in data_frame_seleccionado.columns if col.startswith('DEPARTAMENTO_')] + \
    [col for col in data_frame_seleccionado.columns if col.startswith('SUBSECTOR_ECONOMICO_') or col == 'SUBSECTOR_ECONOMICO_BIN'] + \
    [col for col in data_frame_seleccionado.columns if col.startswith('TIPO_INFRACCION_')]

# Crear DataFrame final
df_final = data_frame_seleccionado[columns_to_extract].copy()
df_final.dropna(inplace=True)

# Normalización
scaler = StandardScaler()
df_final[columns_to_extract] = scaler.fit_transform(df_final[columns_to_extract])

# Búsqueda de cantidad óptima de clusters
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, max_iter=300, random_state=42, n_init=10)
    kmeans.fit(df_final)
    wcss.append(kmeans.inertia_)

# Graficar el Codo de Jambú
plt.figure(figsize=(10, 8))
plt.plot(range(1, 11), wcss, marker='o')
plt.title('Codo de Jambú')
plt.xlabel('Número de Clusters')
plt.ylabel('WCSS')
plt.show()

# Aplicar K-means al DataFrame
kmeans = KMeans(n_clusters=3, max_iter=3000, random_state=42, n_init=10).fit(df_final)
centroids = kmeans.cluster_centers_

# Convertir el DataFrame a array de NumPy para la gráfica
df_final_array = df_final.to_numpy()

plt.scatter(df_final_array[:,0], df_final_array[:,1], c=kmeans.labels_.astype(float), s=50)
plt.scatter(centroids[:,0], centroids[:,1], c='red', marker='*', s=50)
plt.show()

# Agregar la columna de clusters al DataFrame original
df_final['KMeans_clusters'] = kmeans.labels_

# Guardar el DataFrame con los clusters en un nuevo archivo CSV
df_final.to_csv('NRUIAS.csv', sep=';', index=False)

print("DataFrame con clusters añadido:")
print(df_final.head())